{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263450be",
   "metadata": {},
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c08eb9",
   "metadata": {},
   "source": [
    "**Supervised:** The labels are included in the training data and the goal is to train a model to learn to predict the labels from the features  \n",
    "**Classification:** The label is a binary variable, 0 (will repay loan on time), 1 (will have difficulty repaying loan)\n",
    "\n",
    "- Evaluation des performances des modèles d’apprentissage supervisé selon différents critères (scores, temps d'entraînement, etc.) en adaptant les paramètres afin de choisir le modèle le plus performant pour la problématique métier.\n",
    "- Calcul un score avec fp + 10 * fn\n",
    "\n",
    "precision, recall, accuracy, roc_auc, f1\n",
    "        fbeta_macro\n",
    "        fbeta_micro\n",
    "        fbeta_weighted\n",
    "        \n",
    "hyperparameter search for the following methods: XGBoost, LightGBM, Random Forest. Save each model, best parameters and evaluation metrics with MLflow. Save the evaluation metrics for all models to a dataframe.\n",
    "\n",
    "- [ 0 - Library definition](#0) \n",
    "- [ 1 - Data definition](#1) \n",
    "- [ 1.1 - Imbalanced Data Definition](#1.1) \n",
    "- [ 2 - Metrics definition](#2) \n",
    "- [ 3 - Model definition](#3) \n",
    "- [ 4 - Run 1 EXPERIMENT with 6 RUNs](#4)\n",
    "- [ 5 - Model Evaluation](#(5)\n",
    "- [ 6 - Feature Importance](#(6)\n",
    "- [ 7 - Feature Selection after SHAP feature Importance](#(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3342a76b",
   "metadata": {},
   "source": [
    "<a name='0'></a>\n",
    "# 0 Library definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c8b0045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow import MlflowClient\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from numpy import where\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063e4ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Python documentation found for '1.7.0'.\n",
      "Use help() to get the interactive help utility.\n",
      "Use help(str) for help on the str class.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5c0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip uninstall xgboost\n",
    "#!pip install xgboost==1.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bc9296",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "# 1 Data definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee5e0b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (246008, 239)\n",
      "Y_train (246008, 1)\n",
      "Y_test (61503, 1)\n",
      "ids_test (246008, 1)\n",
      "feature names (239, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.read_csv('../2_INPUT_DATA/3_SPLIT/X_train.csv')\n",
    "Y_train = pd.read_csv('../2_INPUT_DATA/3_SPLIT/Y_train.csv')\n",
    "X_test = pd.read_csv('../2_INPUT_DATA/3_SPLIT/X_test.csv')\n",
    "Y_test = pd.read_csv('../2_INPUT_DATA/3_SPLIT/Y_test.csv')\n",
    "ids_test = pd.read_csv('../2_INPUT_DATA/3_SPLIT/ids_test.csv')\n",
    "feature_names = pd.read_csv('../2_INPUT_DATA/2_FEATURE_PROCESSED/feature_names.csv')\n",
    "\n",
    "print(\"X_train\", X_train.shape)\n",
    "print(\"Y_train\", Y_train.shape)\n",
    "print(\"Y_test\", Y_test.shape)\n",
    "print(\"ids_test\",ids_test.shape)\n",
    "print(\"feature names\", feature_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4a4c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(df_train, df_test):\n",
    "    \"\"\"\n",
    "    Scale the features in the training and testing datasets using Min-Max scaling.\n",
    "\n",
    "    Args:\n",
    "    df_train (DataFrame): The training dataset to be scaled.\n",
    "    df_test (DataFrame): The testing dataset to be scaled.\n",
    "\n",
    "    Returns:\n",
    "    df_train_scaled (DataFrame): The scaled training dataset.\n",
    "    df_test_scaled (DataFrame): The scaled testing dataset.\n",
    "    \"\"\"\n",
    "    # Initialize MinMaxScaler with feature range between 0 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    # Fit and transform the training dataset\n",
    "    df_train_scaled = scaler.fit_transform(df_train)\n",
    "\n",
    "    # Transform the testing dataset using the same scaler fitted on the training data\n",
    "    df_test_scaled = scaler.transform(df_test)\n",
    "\n",
    "    return df_train_scaled, df_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bede7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = X_train.copy()\n",
    "#test[\"ID\"] = ids_test\n",
    "#test.set_index(\"ID\", inplace=True)\n",
    "#ids_test.iloc[5]\n",
    "#test.loc[100008].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058db3e2",
   "metadata": {},
   "source": [
    "<a name='1.1'></a>\n",
    "# 1.1 Imbalanced Data treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50308a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 226067, 1: 19941})\n",
      "Counter({0: 45212, 1: 22606})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def SMOTE_transformation(X, y):\n",
    "    # summarize class distribution\n",
    "    counter = Counter(y)\n",
    "    print(counter)\n",
    "    # define pipeline\n",
    "    over = SMOTE(sampling_strategy=0.1)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    # transform the dataset\n",
    "    X, y = pipeline.fit_resample(X, y)\n",
    "    # summarize the new class distribution\n",
    "    counter = Counter(y)\n",
    "    print(counter)\n",
    "    # scatter plot of examples by class label\n",
    "    #for label, _ in counter.items():\n",
    "    #    print(label)\n",
    "    #    row_ix = where(y == label)[0]\n",
    "    #    print(row_ix)\n",
    "    #    pyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
    "        \n",
    "    #pyplot.legend()\n",
    "    #pyplot.show()\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "x_train_smote, y_train_smote = SMOTE_transformation(X_train, Y_train['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1cdbe1",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "# 2 Metrics definition\n",
    "\n",
    "**Fbeta Score**\n",
    "\n",
    "![alt text for screen readers](IMAGES/fbetascore.png \"Fbeta Score\")\n",
    "\n",
    "A smaller beta value, such as 0.5, gives more weight to precision and less to recall, whereas a larger beta value, such as 2.0, gives less weight to precision and more weight to recall in the calculation of the score.\n",
    "\n",
    "#### FN et FP  \n",
    "On simule la supposition, que le coût d’un FN est dix fois supérieur au coût d’un FP.  \n",
    "On crée un score “métier” en minimisant le coût d’erreur de prédiction des FN et FP pour comparer les modèles, afin de choisir le meilleur modèle et ses meilleurs hyperparamètres.\n",
    "\n",
    "**Precision**  \n",
    "(tp / (tp + fp))\n",
    "It describes how good a model is at predicting the positive class. Precision is referred to as the positive predictive value.  \n",
    "\n",
    "**Recall** is the same as sensitivity.\n",
    "(tp / (tp + fn)    \n",
    "Recall describes how good the model is at predicting the positive class when the actual outcome is positive.\n",
    "\n",
    "\n",
    "We want to optimize recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d982f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fbeta_score_calculation(y_true, y_pred):\n",
    "    fbeta_macro = fbeta_score(y_true, y_pred, average='macro', beta=2)\n",
    "    fbeta_micro = fbeta_score(y_true, y_pred, average='micro', beta=2)\n",
    "    fbeta_weighted = fbeta_score(y_true, y_pred, average='weighted', beta=2)\n",
    "    return round(fbeta_macro,2), round(fbeta_micro,2), round(fbeta_weighted,2)\n",
    "\n",
    "def plot_roc_curve(true_y, y_prob):\n",
    "    \"\"\"\n",
    "    plots the roc curve based of the probabilities\n",
    "    \"\"\"\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(true_y, y_prob)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "def reminder_TP(TN=\"\", FP=\"\", FN=\"\", TP=\"\"):\n",
    "    #tn, fp, fn, tp\n",
    "    # Create a PrettyTable instance\n",
    "    table = PrettyTable()\n",
    "\n",
    "    # Define columns and headers\n",
    "    table.field_names = ['Confusion Matrix', 'Positive prediction', 'Negative prediction']\n",
    "\n",
    "    # Add rows\n",
    "    table.add_row(['Positive class', 'True positive (TP)', 'False negative (FN)'])\n",
    "    table.add_row(['Negative class', 'False positive (FP)', 'True negative (TN)'])\n",
    "\n",
    "    # Print the table\n",
    "    print(table)\n",
    "    \n",
    "    if TN :\n",
    "        # Create a PrettyTable instance\n",
    "        table2 = PrettyTable()\n",
    "\n",
    "        # Define columns and headers\n",
    "        table2.field_names = ['Confusion Matrix', 'Positive prediction', 'Negative prediction']\n",
    "\n",
    "        # Add rows\n",
    "        table2.add_row(['Positive class', TP, FN])\n",
    "        table2.add_row(['Negative class', FP, TN])\n",
    "\n",
    "        # Print the table\n",
    "        print(table2)\n",
    "    \n",
    "\n",
    "def generate_recall_precision_curve(model, X_test, Y_test):\n",
    "    # predict probabilities\n",
    "    lr_probs = model.predict_proba(X_test)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    # predict class values\n",
    "    yhat = model.predict(X_test)\n",
    "    lr_precision, lr_recall, _ = precision_recall_curve(Y_test, lr_probs)\n",
    "    lr_f1, lr_auc = f1_score(Y_test, yhat), auc(lr_recall, lr_precision)\n",
    "    # summarize scores\n",
    "    print('Logistic: f1=%.3f auc=%.3f' % (lr_f1, lr_auc))\n",
    "    # plot the precision-recall curves\n",
    "    no_skill = len(Y_test[Y_test==1]) / len(Y_test)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "    plt.plot(lr_recall, lr_precision, marker='.', label='Logistic')\n",
    "    # axis labels\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "def generate_auc_roc_curve(clf, X_test):\n",
    "    y_pred_proba = clf.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(Y_test,  y_pred_proba)\n",
    "    auc = roc_auc_score(Y_test, y_pred_proba)\n",
    "    plt.plot(fpr,tpr,label=\"AUC ROC Curve with Area Under the curve =\"+str(auc))\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    pass\n",
    "\n",
    "def generate_model_report(model, model_name, X_test, Y_test, trainT):\n",
    "    print(\"\\n---------------------------------\")\n",
    "    print(\"start generate_model_report\")\n",
    "    \n",
    "    Y_Test_Pred_best_param = model.predict(X_test)\n",
    "    \n",
    "    generate_auc_roc_curve(model, X_test)\n",
    "    generate_recall_precision_curve(model, X_test, Y_test)\n",
    "    \n",
    "    cm = confusion_matrix(np.array(Y_test), Y_Test_Pred_best_param  )\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    reminder_TP(tn, fp, fn, tp)\n",
    "    \n",
    "    roc_auc = roc_auc_score(np.array(Y_test), Y_Test_Pred_best_param)\n",
    "\n",
    "    bu_Sc = fp + (10*fn) #business score FN cost 10 times more than fp\n",
    "    ac_Sc = accuracy_score(np.array(Y_test), Y_Test_Pred_best_param)\n",
    "    pr_Sc = precision_score(np.array(Y_test), Y_Test_Pred_best_param)\n",
    "    re_Sc = recall_score(np.array(Y_test), Y_Test_Pred_best_param)\n",
    "    F1_Sc = f1_score(np.array(Y_test), Y_Test_Pred_best_param)\n",
    "    fbeta_macro, fbeta_micro, fbeta_weighted = fbeta_score_calculation(np.array(Y_test), Y_Test_Pred_best_param)\n",
    "    print('ROC AUC: ', roc_auc)\n",
    "    print(\"Accuracy = \" , accuracy_score(np.array(Y_test), Y_Test_Pred_best_param))\n",
    "    print(\"Precision = \" ,precision_score(np.array(Y_test), Y_Test_Pred_best_param))\n",
    "    print(\"Recall = \" ,recall_score(np.array(Y_test), Y_Test_Pred_best_param))\n",
    "    print(\"F1 Score = \" ,f1_score(np.array(Y_test), Y_Test_Pred_best_param))\n",
    "    print(\"Fbeta Score = \" ,fbeta_score_calculation(np.array(Y_test), Y_Test_Pred_best_param))\n",
    "    \n",
    "    metrics = pd.DataFrame({'model': model_name,'tn': [tn], 'fp': [fp], 'fn': [fn], 'tp': [tp],'FP+10*FN': bu_Sc,\n",
    "                            'accuracy': [ac_Sc], \n",
    "                            'ROC_AUC': [roc_auc],\n",
    "                            'precision': [pr_Sc],\n",
    "                            'recall': [re_Sc],\n",
    "                            'F1_Score': [F1_Sc],\n",
    "                            'Fbeta_macro':[fbeta_macro], \n",
    "                            'Fbeta_micro':[fbeta_micro],\n",
    "                            'Fbeta_weighted':[fbeta_weighted]\n",
    "                            })\n",
    "    print(metrics)\n",
    "    \n",
    "    full_threshold_df, metrics_XGB_smote = find_optimal_business_score(model, model_name, X_test, Y_test, trainT)\n",
    "    \n",
    "    return metrics_XGB_smote, full_threshold_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccf49b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_business_score(model, model_name, X_test, Y_true, trainT):\n",
    "    print(\"---------------------------------\")\n",
    "    print(\"start find_optimal_business_score\")\n",
    "    predictions_proba = model.predict_proba(X_test)\n",
    "    \n",
    "    print(\"prediction proba\", len(predictions_proba))\n",
    "    print(\"Y_true\", len(Y_true))\n",
    "\n",
    "    # Threshold values from 0 to 0.5\n",
    "    threshold_values = [i / 10 for i in range(6)]\n",
    "    best_B_score = 100000\n",
    "    \n",
    "    # Create an empty DataFrame to store results\n",
    "    results_df = pd.DataFrame(columns=['threshold', 'tn', 'fp', 'fn', 'tp', 'FP+10*FN', 'accuracy', 'ROC_AUC', 'precision', 'recall', 'F1_Score', 'Fbeta_macro', 'Fbeta_micro', 'Fbeta_weighted','best'])\n",
    "\n",
    "    # Loop through threshold values\n",
    "    for threshold in threshold_values:\n",
    "        best = 0\n",
    "        # Convert probabilities to binary predictions based on threshold\n",
    "        predicted_labels = [1 if x[1] >= threshold else 0 for x in predictions_proba]\n",
    "\n",
    "        # Calculate confusion matrix and other metrics\n",
    "        cm = confusion_matrix(Y_true, predicted_labels)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        FP_10_FN = fp + 10 * fn\n",
    "        precision = precision_score(Y_true, predicted_labels)\n",
    "        recall = recall_score(Y_true, predicted_labels)\n",
    "        accuracy = accuracy_score(Y_true, predicted_labels)\n",
    "        roc_auc = roc_auc_score(Y_true, predicted_labels)\n",
    "        f1 = f1_score(Y_true, predicted_labels)\n",
    "        fbeta_macro = fbeta_score(Y_true, predicted_labels, beta=2, average='macro')\n",
    "        fbeta_micro = fbeta_score(Y_true, predicted_labels, beta=2, average='micro')\n",
    "        fbeta_weighted = fbeta_score(Y_true, predicted_labels, beta=2, average='weighted')\n",
    "\n",
    "        # best param\n",
    "        if (best_B_score > FP_10_FN ):\n",
    "            print(results_df[results_df['best']==1]['best'])\n",
    "            results_df.loc[(results_df['best']==1),'best']  = 0\n",
    "            best_B_score = FP_10_FN\n",
    "            best = 1\n",
    "        \n",
    "        \n",
    "        # Create a DataFrame for the current threshold iteration\n",
    "        data = {'threshold': [threshold],\n",
    "                'tn': [tn],\n",
    "                'fp': [fp],\n",
    "                'fn': [fn],\n",
    "                'tp': [tp],\n",
    "                'FP+10*FN': [FP_10_FN],\n",
    "                'accuracy': [accuracy],\n",
    "                'ROC_AUC': [roc_auc],\n",
    "                'precision': [precision],\n",
    "                'recall': [recall],\n",
    "                'F1_Score': [f1],\n",
    "                'Fbeta_macro': [fbeta_macro],\n",
    "                'Fbeta_micro': [fbeta_micro],\n",
    "                'Fbeta_weighted': [fbeta_weighted],\n",
    "                'best': best\n",
    "               }\n",
    "\n",
    "        threshold_df = pd.DataFrame(data)\n",
    "\n",
    "        # Concatenate the current threshold results to the overall results DataFrame\n",
    "        results_df = pd.concat([results_df, threshold_df], ignore_index=True)\n",
    "        \n",
    "    \n",
    "    best_result = results_df[results_df['best']==1]\n",
    "    \n",
    "    best_metrics = {\"TN\":best_result[\"tn\"].iloc[0],\n",
    "                  \"FP\":best_result[\"fp\"].iloc[0],\n",
    "                  \"FN\":best_result[\"fn\"].iloc[0],\n",
    "                  \"TP\":best_result[\"tp\"].iloc[0],\n",
    "                  \"FP_10_FN\":best_result[\"FP+10*FN\"].iloc[0],\n",
    "                  \"Accuracy\": best_result[\"accuracy\"].iloc[0],\n",
    "                 \"F1\":best_result[\"F1_Score\"].iloc[0],\n",
    "                 \"Precision\":best_result[\"precision\"].iloc[0],\n",
    "                 \"Recall\":best_result[\"recall\"].iloc[0],\n",
    "                 \"ROC_AUC\":best_result[\"ROC_AUC\"].iloc[0],\n",
    "                \"threshold\":best_result[\"threshold\"].iloc[0],\n",
    "                    \"time_in_s\":trainT\n",
    "                 }\n",
    "    \n",
    "    print(\"best b score\", best_B_score, results_df[results_df['best']==1]['threshold'])\n",
    "    print(results_df)\n",
    "    return results_df, best_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cad3596",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "# 3 Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42ab1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFC_model(X_train, Y_train) :\n",
    "    \"\"\"Train RandomForestClassifier model using GridSearchCV.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): The input features for training.\n",
    "        Y_train (pd.Series): The target labels for training.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the best RandomForestClassifier model, best hyperparameters, and training duration.\n",
    "\n",
    "    \"\"\"\n",
    "    # Start timing the function\n",
    "    start = time.time()\n",
    "    print(\"START time\", time.ctime(start))\n",
    "    \n",
    "    # Define the RandomForestClassifier\n",
    "    rf_classifier = RandomForestClassifier()\n",
    "\n",
    "    # Define the hyperparameter grid for GridSearchCV\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200],          # Number of trees in the forest\n",
    "        'max_depth': [None, 10, 20],              # Maximum depth of the tree\n",
    "        'min_samples_split': [2, 5, 10],          # Minimum number of samples required to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 4]             # Minimum number of samples required to be at a leaf node\n",
    "    }\n",
    "\n",
    "    # Create the GridSearchCV object\n",
    "    grid_search = GridSearchCV(rf_classifier, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Perform the grid search on the training data\n",
    "    grid_search.fit(X_train, Y_train)\n",
    "\n",
    "    # Get the best hyperparameters from the grid search\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Train the RandomForestClassifier with the best hyperparameters on the entire training set\n",
    "    best_rf_classifier = RandomForestClassifier(**best_params)\n",
    "    best_rf_classifier.fit(X_train, Y_train)\n",
    "\n",
    "    # Print the best hyperparameters\n",
    "    print(f'Best Hyperparameters: {best_params}')\n",
    "\n",
    "    # End timing the function\n",
    "    end = time.time()\n",
    "    endT = end - start\n",
    "    print(\"START time\", time.ctime(start))\n",
    "    print(\"END time\", time.ctime(end), ' duration', endT/60 , 'min')\n",
    "    \n",
    "    # Return the best RandomForestClassifier model, best hyperparameters, and the duration of training\n",
    "    return best_rf_classifier, best_params, endT\n",
    "\n",
    "def train_XGBoost_model(X_train: pd.DataFrame, Y_train: pd.Series):\n",
    "    \"\"\"Train XGBoost model using RandomizedSearchCV.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): The input features for training.\n",
    "        Y_train (pd.Series): The target labels for training.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the best XGBoost model, best hyperparameters, and training duration.\n",
    "\n",
    "    \"\"\"\n",
    "    # Start timing the function\n",
    "    start = time.time()\n",
    "    print(\"START time\", time.ctime(start))\n",
    "    \n",
    "    # Define hyperparameters for XGBoost model\n",
    "    xgb_params = {\n",
    "        'n_estimators': [*range(170, 200, 5)],  # Range of values for the number of trees\n",
    "        'max_depth': [6],  # Maximum depth of a tree\n",
    "        'learning_rate': [0.1],  # Learning rate\n",
    "        'subsample': [0.3],  # Subsample ratio of the training instances\n",
    "        'colsample_bytree': [0.3]  # Subsample ratio of columns when constructing each tree\n",
    "    }\n",
    "\n",
    "    # Initialize XGBoost classifier\n",
    "    xgb_model = XGBClassifier()\n",
    "\n",
    "    # Perform RandomizedSearchCV to find the best hyperparameters\n",
    "    print(\"start RandomizedSearchCV \")\n",
    "    xgb_random_search = RandomizedSearchCV(xgb_model, param_distributions=xgb_params, n_iter=100, cv=5, n_jobs=-1, verbose=6, error_score='raise')\n",
    "    xgb_random_search.fit(X_train, Y_train)\n",
    "    \n",
    "    # Access the best hyperparameters and the best models\n",
    "    best_xgb_params = xgb_random_search.best_params_\n",
    "    best_xgb_model = xgb_random_search.best_estimator_\n",
    "    \n",
    "    param = {'booster': 'dart',\n",
    "         'max_depth': 5, 'learning_rate': 0.1,\n",
    "         'objective': 'binary:logistic',\n",
    "         'sample_type': 'uniform',\n",
    "         'normalize_type': 'tree',\n",
    "         'rate_drop': 0.1,\n",
    "         'skip_drop': 0.5}\n",
    "    num_round = 50\n",
    "    #best_xgb_model = xgb_model.fit(param, X_train, Y_train, num_round)\n",
    "    #best_xgb_params = param\n",
    "    \n",
    "    \n",
    "    \n",
    "    # End timing the function\n",
    "    end = time.time()\n",
    "    endT = end - start\n",
    "    print(\"START time\", time.ctime(start))\n",
    "    print(\"END time\", time.ctime(end), ' duration', endT/60 , 'min')\n",
    "    \n",
    "    # Return the best XGBoost model, best hyperparameters, and the duration of training\n",
    "    return best_xgb_model, best_xgb_params, endT\n",
    "\n",
    "def train_LightGBM_model(X_train: pd.DataFrame, Y_train: pd.Series) -> tuple:\n",
    "    \"\"\"Train LightGBM model using RandomizedSearchCV.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): The input features for training.\n",
    "        Y_train (pd.Series): The target labels for training.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the best LightGBM model, best hyperparameters, and training duration.\n",
    "\n",
    "    \"\"\"\n",
    "    # Start timing the function\n",
    "    start = time.time()\n",
    "    print(\"START time\", time.ctime(time.time()))\n",
    "    \n",
    "    \n",
    "    # Define hyperparameters for LightGBM model\n",
    "    lgbm_params = {\n",
    "        'boosting_type': ['gbdt'],           # Gradient boosting type\n",
    "        'n_estimators': [10000],             # Number of boosting iterations\n",
    "        'objective': ['binary'],             # Objective function (binary classification)\n",
    "        'metric': ['binary_logloss'],        # Evaluation metric\n",
    "        'num_leaves': [31],                  # Maximum number of leaves in one tree\n",
    "        'learning_rate': [0.05],             # Learning rate\n",
    "        'class_weight' : ['balanced'],       # Weights associated with classes\n",
    "        'reg_alpha' : [0.1],                 # L1 regularization term\n",
    "        'reg_lambda' : [0.1],                # L2 regularization term\n",
    "        'subsample' : [ 0.8 ]                # Subsample ratio of the training instances\n",
    "    }\n",
    "    # Best hyperparameters are commented out for reference\n",
    "\n",
    "    # Initialize LightGBM classifier\n",
    "    lgbm_model = LGBMClassifier()\n",
    "\n",
    "    # Perform RandomizedSearchCV to find the best hyperparameters\n",
    "    lgbm_random_search = RandomizedSearchCV(lgbm_model, param_distributions=lgbm_params, n_iter=100, cv=5, n_jobs=-1, verbose=5)\n",
    "    lgbm_random_search.fit(X_train, Y_train)\n",
    "\n",
    "    # Access the best hyperparameters and the best models\n",
    "    best_lgbm_params = lgbm_random_search.best_params_\n",
    "    best_lgbm_model = lgbm_random_search.best_estimator_\n",
    "\n",
    "    # End timing the function\n",
    "    end = time.time()\n",
    "    endT = end - start\n",
    "    print(\"START time\", time.ctime(start))\n",
    "    print(\"END time\", time.ctime(end), ' duration', endT/60 , 'min')\n",
    "    \n",
    "    # Return the best LightGBM model, best hyperparameters, and the duration of training\n",
    "    return best_lgbm_model, best_lgbm_params, endT\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6ed98b",
   "metadata": {},
   "source": [
    "**Train models and save model, params to MLflow and the evaluation metrics to a dataframe**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b224bd54",
   "metadata": {},
   "source": [
    "The following command in Terminal to start the MLflow server  \n",
    "```!mlflow server --host 127.0.0.1 --port 8080```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ca7ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_MLflow(experiment_name, run_name, metrics, params, model_obj, X_train):\n",
    "    mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "    # Sets the current active experiment to the \"LightGBM_Models\" experiment and returns the Experiment metadata\n",
    "    mlflow_experiment = mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    # Define an artifact path that the model will be saved to.\n",
    "    artifact_path = run_name+\"_artifactPATH\"\n",
    "    print(\"Artifact PATH\" , artifact_path)\n",
    "    \n",
    "    # Assemble the metrics we're going to write into a collection\n",
    "    print(metrics)\n",
    "    print(params)\n",
    "    \n",
    "    signature = infer_signature(X_train, model_obj.predict(X_train))\n",
    "\n",
    "    # Initiate the MLflow run context\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        #run = mlflow.active_run()\n",
    "        print(f\"Active run_id: {run.info.run_id}\")\n",
    "        # Log the parameters used for the model fit\n",
    "        mlflow.log_params(params)\n",
    "         # Log parameters and metrics with MLflow\n",
    "        #for key, value in params.items():\n",
    "        #    mlflow.log_param(key, value)\n",
    "        # Log the error metrics that were calculated during validation\n",
    "        mlflow.log_metrics(metrics)\n",
    "        # Log an instance of the trained model for later use\n",
    "        mlflow.sklearn.log_model(sk_model=model_obj, artifact_path=artifact_path, signature=signature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6cab8a",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "# 4 Run 1 EXPERIMENT with 6 RUNs\n",
    "\n",
    "**Unbalanced Data**\n",
    "* Random Forest Classifier RFC\n",
    "* XGBoost XGB\n",
    "* LightGBM LGBM\n",
    "\n",
    "**SMOTE transformed Data**\n",
    "* Random Forest Classifier RFC\n",
    "* XGBoost XGB\n",
    "* LightGBM LGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8df72b",
   "metadata": {},
   "source": [
    "**Initiate MLFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63f2cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080/\")\n",
    "# Provide an Experiment description that will appear in the UI\n",
    "experiment_description = (\n",
    "    \"This is the credit score project. \"\n",
    "    \"This experiment contains the LightGBM, XGboost and RFC model.\"\n",
    ")\n",
    "\n",
    "# Provide searchable tags that define characteristics of the Runs that will be in this Experiment\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"credit-score-classification\",\n",
    "    \"store_dept\": \"Prêt à dépenser\",\n",
    "    \"team\": \"cred-ml\",\n",
    "    \"project_quarter\": \"Q1-2024\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "experiment_name = \"Credit_scoring\"\n",
    "# Create the Experiment, providing a unique name\n",
    "#experiment = client.create_experiment(name=experiment_name, tags=experiment_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6712832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad474b89",
   "metadata": {},
   "source": [
    "**1/6 RUN XGB with unbalanced data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccefa55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45af51da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train_XGBoost_model\n",
      "Artifact PATH XGB_artifactPATH\n",
      "{'TN': 43984, 'FP': 12635, 'FN': 2004, 'TP': 2880, 'FP_10_FN': 32675, 'Accuracy': 0.7619790904508723, 'F1': 0.28236678268542575, 'Precision': 0.18562681276184337, 'Recall': 0.5896805896805897, 'ROC_AUC': 0.6832611429654825, 'threshold': 0.1, 'time_in_s': 855.8744430541992}\n",
      "{'subsample': 0.3, 'n_estimators': 175, 'max_depth': 6, 'learning_rate': 0.1, 'colsample_bytree': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run_id: fe48df8a9e1349daadf27344650588d1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setuptools is replacing distutils.\n"
     ]
    }
   ],
   "source": [
    "# XGB no SMOTE data   \n",
    "run_name = \"XGB\"\n",
    "print(\"start train_XGBoost_model\")\n",
    "#best_xgb_model, best_xgb_params, timeXGB = train_XGBoost_model(X_train, Y_train)    \n",
    "#XGB_metrics, best_XGB  = generate_model_report(best_xgb_model, run_name, X_test, Y_test, timeXGB)\n",
    "run_MLflow(experiment_name, run_name, XGB_metrics, best_xgb_params, best_xgb_model, X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c93a91",
   "metadata": {},
   "source": [
    "**2/6 RUN XGB with SMOTE data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "434d4c2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGB_model_smote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m run_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGB_smote\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#XGB_model_smote, best_xfb_params_smote, timeXGBsmote =  train_XGBoost_model(x_train_smote, y_train_smote)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m XGB_smote_metrics, best_XGB_smote     \u001b[38;5;241m=\u001b[39m generate_model_report(\u001b[43mXGB_model_smote\u001b[49m, run_name, X_test, Y_test, timeXGBsmote)\n\u001b[1;32m      5\u001b[0m run_MLflow(experiment_name, run_name, XGB_smote_metrics, best_xfb_params_smote, XGB_model_smote, x_train_smote)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'XGB_model_smote' is not defined"
     ]
    }
   ],
   "source": [
    "# XGB with SMOTE data   \n",
    "run_name = \"XGB_smote\"\n",
    "XGB_model_smote, best_xfb_params_smote, timeXGBsmote =  train_XGBoost_model(x_train_smote, y_train_smote)\n",
    "XGB_smote_metrics, best_XGB_smote     = generate_model_report(XGB_model_smote, run_name, X_test, Y_test, timeXGBsmote)\n",
    "run_MLflow(experiment_name, run_name, XGB_smote_metrics, best_xfb_params_smote, XGB_model_smote, x_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a909db02",
   "metadata": {},
   "source": [
    "**3/6 LightGBM on unbalanced data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68417fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"LightGBM\"\n",
    "LGBM_model, best_LGBM_params, time_LGBM =  train_LightGBM_model(X_train, Y_train)\n",
    "metrics_LGBM, LGBM_metrics     = generate_model_report(LGBM_model, run_name, X_test, Y_test, time_LGBM)\n",
    "run_MLflow(experiment_name, run_name, metrics_LGBM, best_LGBM_params, LGBM_model, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af8163c",
   "metadata": {},
   "source": [
    "**4/6 LightGBM on smote data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f3789",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"LightGBM_smote\"\n",
    "LGBM_smote_model, best_LGBM_smote_params, time_LGBM_smote =  train_LightGBM_model(x_train_smote, y_train_smote)\n",
    "metrics_LGBM_smote, LGBM_smote_metrics     = generate_model_report(LGBM_smote_model, run_name, X_test, Y_test, time_LGBM_smote)\n",
    "run_MLflow(experiment_name, run_name, metrics_LGBM_smote, best_LGBM_smote_params,\n",
    "           LGBM_smote_model, x_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67893829",
   "metadata": {},
   "source": [
    "**5/6 RFC on unbalanced data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3b1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"RFC\"\n",
    "RFC_model, best_RFC_params, time_RFC = RFC_model(X_train, Y_train)\n",
    "RFC_metrics, best_metrics_RFC        = generate_model_report(RFC_model, run_name, X_test, Y_test, time_RFC)\n",
    "run_MLflow(experiment_name, run_name, RFC_metrics, \n",
    "           best_RFC_params, RFC_model, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44e3f40",
   "metadata": {},
   "source": [
    "**6/6 RFC on Smote data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8449b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"RFC_smote\"\n",
    "RFC_model_smote, best_RFC_params_smote, time_RFC_smote = RFC_model(x_train_smote, y_train_smote)\n",
    "RFC_smote_metrics, best_metrics_RFC_smote              = generate_model_report(RFC_model_smote, run_name, X_test, Y_test, time_RFC_smote)\n",
    "run_MLflow(experiment_name, run_name, RFC_smote_metrics, \n",
    "           best_RFC_params_smote, RFC_model_smote, x_train_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e08b8cf",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "# 5 Evalutation and selection of best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73845c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Experiment: artifact_location='mlflow-artifacts:/695381234922981285', creation_time=1709032914891, experiment_id='695381234922981285', last_update_time=1709032914891, lifecycle_stage='active', name='Credit_scoring', tags={'mlflow.note.content': 'This is the credit score project. This experiment '\n",
      "                        'contains the LightGBM, XGboost and RFC model.',\n",
      " 'project_name': 'credit-score-classification',\n",
      " 'project_quarter': 'Q1-2024',\n",
      " 'store_dept': 'Prêt à dépenser',\n",
      " 'team': 'cred-ml'}>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FP_10_FN</th>\n",
       "      <th>ROC_AUC</th>\n",
       "      <th>t_in_min</th>\n",
       "      <th>FP</th>\n",
       "      <th>TP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>threshold</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Run Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>32675.0</td>\n",
       "      <td>0.683261</td>\n",
       "      <td>14.3</td>\n",
       "      <td>12635.0</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>43984.0</td>\n",
       "      <td>0.761979</td>\n",
       "      <td>0.589681</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.185627</td>\n",
       "      <td>0.282367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>32675.0</td>\n",
       "      <td>0.683261</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12635.0</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>43984.0</td>\n",
       "      <td>0.761979</td>\n",
       "      <td>0.589681</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.185627</td>\n",
       "      <td>0.282367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>32675.0</td>\n",
       "      <td>0.683261</td>\n",
       "      <td>16.1</td>\n",
       "      <td>12635.0</td>\n",
       "      <td>2880.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>43984.0</td>\n",
       "      <td>0.761979</td>\n",
       "      <td>0.589681</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.185627</td>\n",
       "      <td>0.282367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB_Shap002</th>\n",
       "      <td>32718.0</td>\n",
       "      <td>0.683261</td>\n",
       "      <td>6.7</td>\n",
       "      <td>12948.0</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>43671.0</td>\n",
       "      <td>0.757329</td>\n",
       "      <td>0.595209</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.183349</td>\n",
       "      <td>0.280341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB_Shap002_scaled</th>\n",
       "      <td>32846.0</td>\n",
       "      <td>0.681793</td>\n",
       "      <td>7.1</td>\n",
       "      <td>12836.0</td>\n",
       "      <td>2883.0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>43783.0</td>\n",
       "      <td>0.758760</td>\n",
       "      <td>0.590295</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.183409</td>\n",
       "      <td>0.279862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB_smote</th>\n",
       "      <td>33112.0</td>\n",
       "      <td>0.686744</td>\n",
       "      <td>3.2</td>\n",
       "      <td>18292.0</td>\n",
       "      <td>3402.0</td>\n",
       "      <td>1482.0</td>\n",
       "      <td>38327.0</td>\n",
       "      <td>0.678487</td>\n",
       "      <td>0.696560</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.156818</td>\n",
       "      <td>0.256001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB_smote</th>\n",
       "      <td>33198.0</td>\n",
       "      <td>0.685774</td>\n",
       "      <td>6.4</td>\n",
       "      <td>18228.0</td>\n",
       "      <td>3387.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>38391.0</td>\n",
       "      <td>0.679284</td>\n",
       "      <td>0.693489</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.156697</td>\n",
       "      <td>0.255632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM_smote</th>\n",
       "      <td>33281.0</td>\n",
       "      <td>0.681904</td>\n",
       "      <td>5.8</td>\n",
       "      <td>16081.0</td>\n",
       "      <td>3164.0</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>40538.0</td>\n",
       "      <td>0.710567</td>\n",
       "      <td>0.647830</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.164406</td>\n",
       "      <td>0.262257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_Shap002_scaled</th>\n",
       "      <td>34979.0</td>\n",
       "      <td>0.663112</td>\n",
       "      <td>8.1</td>\n",
       "      <td>15079.0</td>\n",
       "      <td>2894.0</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>41540.0</td>\n",
       "      <td>0.722469</td>\n",
       "      <td>0.592547</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.161019</td>\n",
       "      <td>0.253227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC_smote</th>\n",
       "      <td>35067.0</td>\n",
       "      <td>0.655639</td>\n",
       "      <td>25.2</td>\n",
       "      <td>10407.0</td>\n",
       "      <td>2418.0</td>\n",
       "      <td>2466.0</td>\n",
       "      <td>46212.0</td>\n",
       "      <td>0.790693</td>\n",
       "      <td>0.495086</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.188538</td>\n",
       "      <td>0.273081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC_newFEATURE_002</th>\n",
       "      <td>35370.0</td>\n",
       "      <td>0.661839</td>\n",
       "      <td>93.9</td>\n",
       "      <td>17020.0</td>\n",
       "      <td>3049.0</td>\n",
       "      <td>1835.0</td>\n",
       "      <td>39599.0</td>\n",
       "      <td>0.693430</td>\n",
       "      <td>0.624283</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.151926</td>\n",
       "      <td>0.244379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>35415.0</td>\n",
       "      <td>0.659149</td>\n",
       "      <td>13.3</td>\n",
       "      <td>15435.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>41184.0</td>\n",
       "      <td>0.716550</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.157524</td>\n",
       "      <td>0.248739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>35415.0</td>\n",
       "      <td>0.659149</td>\n",
       "      <td>8.3</td>\n",
       "      <td>15435.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>41184.0</td>\n",
       "      <td>0.716550</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.157524</td>\n",
       "      <td>0.248739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM_smote</th>\n",
       "      <td>35415.0</td>\n",
       "      <td>0.659149</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15435.0</td>\n",
       "      <td>2886.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>41184.0</td>\n",
       "      <td>0.716550</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.157524</td>\n",
       "      <td>0.248739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM_Shap002</th>\n",
       "      <td>35429.0</td>\n",
       "      <td>0.658589</td>\n",
       "      <td>8.5</td>\n",
       "      <td>15139.0</td>\n",
       "      <td>2855.0</td>\n",
       "      <td>2029.0</td>\n",
       "      <td>41480.0</td>\n",
       "      <td>0.720859</td>\n",
       "      <td>0.584562</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.158664</td>\n",
       "      <td>0.249585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC_newFEATURE</th>\n",
       "      <td>36534.0</td>\n",
       "      <td>0.653852</td>\n",
       "      <td>204.3</td>\n",
       "      <td>19814.0</td>\n",
       "      <td>3212.0</td>\n",
       "      <td>1672.0</td>\n",
       "      <td>36805.0</td>\n",
       "      <td>0.650651</td>\n",
       "      <td>0.657658</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.139494</td>\n",
       "      <td>0.230168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC_newFEATURE_001</th>\n",
       "      <td>36741.0</td>\n",
       "      <td>0.651827</td>\n",
       "      <td>226.9</td>\n",
       "      <td>19881.0</td>\n",
       "      <td>3198.0</td>\n",
       "      <td>1686.0</td>\n",
       "      <td>36738.0</td>\n",
       "      <td>0.649334</td>\n",
       "      <td>0.654791</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.138568</td>\n",
       "      <td>0.228731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>37838.0</td>\n",
       "      <td>0.642491</td>\n",
       "      <td>502.6</td>\n",
       "      <td>21228.0</td>\n",
       "      <td>3223.0</td>\n",
       "      <td>1661.0</td>\n",
       "      <td>35391.0</td>\n",
       "      <td>0.627839</td>\n",
       "      <td>0.659910</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.131815</td>\n",
       "      <td>0.219738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFC</th>\n",
       "      <td>37986.0</td>\n",
       "      <td>0.636501</td>\n",
       "      <td>232.0</td>\n",
       "      <td>18046.0</td>\n",
       "      <td>2890.0</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>38573.0</td>\n",
       "      <td>0.674162</td>\n",
       "      <td>0.591728</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.138040</td>\n",
       "      <td>0.223857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     FP_10_FN   ROC_AUC  t_in_min       FP      TP      FN  \\\n",
       "Run Name                                                                     \n",
       "XGB                   32675.0  0.683261      14.3  12635.0  2880.0  2004.0   \n",
       "XGB                   32675.0  0.683261      13.5  12635.0  2880.0  2004.0   \n",
       "XGB                   32675.0  0.683261      16.1  12635.0  2880.0  2004.0   \n",
       "XGB_Shap002           32718.0  0.683261       6.7  12948.0  2907.0  1977.0   \n",
       "XGB_Shap002_scaled    32846.0  0.681793       7.1  12836.0  2883.0  2001.0   \n",
       "XGB_smote             33112.0  0.686744       3.2  18292.0  3402.0  1482.0   \n",
       "XGB_smote             33198.0  0.685774       6.4  18228.0  3387.0  1497.0   \n",
       "LightGBM_smote        33281.0  0.681904       5.8  16081.0  3164.0  1720.0   \n",
       "LGBM_Shap002_scaled   34979.0  0.663112       8.1  15079.0  2894.0  1990.0   \n",
       "RFC_smote             35067.0  0.655639      25.2  10407.0  2418.0  2466.0   \n",
       "RFC_newFEATURE_002    35370.0  0.661839      93.9  17020.0  3049.0  1835.0   \n",
       "LightGBM              35415.0  0.659149      13.3  15435.0  2886.0  1998.0   \n",
       "LightGBM              35415.0  0.659149       8.3  15435.0  2886.0  1998.0   \n",
       "LightGBM_smote        35415.0  0.659149       5.0  15435.0  2886.0  1998.0   \n",
       "LGBM_Shap002          35429.0  0.658589       8.5  15139.0  2855.0  2029.0   \n",
       "RFC_newFEATURE        36534.0  0.653852     204.3  19814.0  3212.0  1672.0   \n",
       "RFC_newFEATURE_001    36741.0  0.651827     226.9  19881.0  3198.0  1686.0   \n",
       "RFC                   37838.0  0.642491     502.6  21228.0  3223.0  1661.0   \n",
       "RFC                   37986.0  0.636501     232.0  18046.0  2890.0  1994.0   \n",
       "\n",
       "                          TN  Accuracy    Recall  threshold  Precision  \\\n",
       "Run Name                                                                 \n",
       "XGB                  43984.0  0.761979  0.589681        0.1   0.185627   \n",
       "XGB                  43984.0  0.761979  0.589681        0.1   0.185627   \n",
       "XGB                  43984.0  0.761979  0.589681        0.1   0.185627   \n",
       "XGB_Shap002          43671.0  0.757329  0.595209        0.1   0.183349   \n",
       "XGB_Shap002_scaled   43783.0  0.758760  0.590295        0.1   0.183409   \n",
       "XGB_smote            38327.0  0.678487  0.696560        0.3   0.156818   \n",
       "XGB_smote            38391.0  0.679284  0.693489        0.3   0.156697   \n",
       "LightGBM_smote       40538.0  0.710567  0.647830        0.3   0.164406   \n",
       "LGBM_Shap002_scaled  41540.0  0.722469  0.592547        0.2   0.161019   \n",
       "RFC_smote            46212.0  0.790693  0.495086        0.4   0.188538   \n",
       "RFC_newFEATURE_002   39599.0  0.693430  0.624283        0.1   0.151926   \n",
       "LightGBM             41184.0  0.716550  0.590909        0.2   0.157524   \n",
       "LightGBM             41184.0  0.716550  0.590909        0.2   0.157524   \n",
       "LightGBM_smote       41184.0  0.716550  0.590909        0.2   0.157524   \n",
       "LGBM_Shap002         41480.0  0.720859  0.584562        0.2   0.158664   \n",
       "RFC_newFEATURE       36805.0  0.650651  0.657658        0.1   0.139494   \n",
       "RFC_newFEATURE_001   36738.0  0.649334  0.654791        0.1   0.138568   \n",
       "RFC                  35391.0  0.627839  0.659910        0.1   0.131815   \n",
       "RFC                  38573.0  0.674162  0.591728        0.1   0.138040   \n",
       "\n",
       "                           F1  \n",
       "Run Name                       \n",
       "XGB                  0.282367  \n",
       "XGB                  0.282367  \n",
       "XGB                  0.282367  \n",
       "XGB_Shap002          0.280341  \n",
       "XGB_Shap002_scaled   0.279862  \n",
       "XGB_smote            0.256001  \n",
       "XGB_smote            0.255632  \n",
       "LightGBM_smote       0.262257  \n",
       "LGBM_Shap002_scaled  0.253227  \n",
       "RFC_smote            0.273081  \n",
       "RFC_newFEATURE_002   0.244379  \n",
       "LightGBM             0.248739  \n",
       "LightGBM             0.248739  \n",
       "LightGBM_smote       0.248739  \n",
       "LGBM_Shap002         0.249585  \n",
       "RFC_newFEATURE       0.230168  \n",
       "RFC_newFEATURE_001   0.228731  \n",
       "RFC                  0.219738  \n",
       "RFC                  0.223857  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the experiment by name\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "print(experiment)\n",
    "# Get all runs within the experiment\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "# Create an empty list to store metrics data\n",
    "metrics_data = []\n",
    "\n",
    "# Iterate over each run and append its metrics to the list\n",
    "for index, run in runs.iterrows():\n",
    "    run_id = run[\"run_id\"]\n",
    "    #print(run_id)\n",
    "    run_info = mlflow.get_run(run_id)\n",
    "    #print(run_info)\n",
    "    run_name = run_info.data.tags.get(\"mlflow.runName\")\n",
    "    metrics = run_info.data.metrics\n",
    "    metrics_data.append({**metrics, \"Run Name\": run_name})\n",
    "\n",
    "# Create a DataFrame from the metrics data\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "metrics_df.set_index(\"Run Name\", inplace=True)  # Set the run name as the index\n",
    "\n",
    "#metrics_df['t_in_s'] = round(metrics_df['time_in_s'],0)\n",
    "metrics_df['t_in_min'] = round(metrics_df['time_in_s']/60,1)\n",
    "#metrics_df['FP_10_FN'] = round(metrics_df['FP_10_FN'],0)\n",
    "\n",
    "#metrics_df.drop(['t_in_s'],axis=1, inplace=True)\n",
    "\n",
    "metrics_df = metrics_df.sort_values(by='FP_10_FN', ascending=True)\n",
    "#print(round(metrics_df,2))\n",
    "#metrics_df = round(metrics_df,2)\n",
    "metrics_out = metrics_df[['FP_10_FN','ROC_AUC','t_in_min','FP','TP','FN','TN','Accuracy','Recall','threshold','Precision','F1']]\n",
    "metrics_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e53b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff01d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model and make predictions\n",
    "logged_model = 'runs:/546a6c80762547cfb2f52e2cfb9bb735/XGB_artifactPATH'\n",
    "\n",
    "xgb_classifier_saved = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f09f03",
   "metadata": {},
   "source": [
    "The model **XGB** receives the best business score (FP_10_FN) with 32675, at the same time it has the second highest Accuracy and the second highest Precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688750c6",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "# 6 Feature Importance\n",
    "\n",
    "- get feature importance\n",
    "- select the features with SHAP values equal 0 and retrain model to assess change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829aa82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_names.iloc[:,0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names.iloc[:,0].values.tolist(),\n",
    "    'Importance': RFC_model.feature_importances_\n",
    "})\n",
    "\n",
    "# Sorting the DataFrame by importance scores\n",
    "feature_importance_df_sorted = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Displaying the sorted DataFrame\n",
    "#feature_importance_df_sorted['Feature'][:20].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4aedda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns with data type 'int64'\n",
    "int_columns = X_train.select_dtypes(include=['int64']).columns\n",
    "\n",
    "# Convert selected columns to int\n",
    "X_train[int_columns] = X_train[int_columns].astype('float')\n",
    "# Select columns with data type 'int64'\n",
    "int_columns = X_train.select_dtypes(include=['bool']).columns\n",
    "\n",
    "# Convert selected columns to int\n",
    "X_train[int_columns] = X_train[int_columns].astype('float')\n",
    "#X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e173c5e8",
   "metadata": {},
   "source": [
    "**Conversion of type of the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_train.copy()\n",
    "test[\"ID\"] = ids_test\n",
    "test.set_index(\"ID\", inplace=True)\n",
    "ids_test.iloc[5]\n",
    "#test.loc[100008].values.tolist()\n",
    "data_point = test.loc[100030].values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_P = pd.DataFrame(data_point)\n",
    "data_P.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ac641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(best_xgb_model, X_train)\n",
    "\n",
    "shap_values = explainer.shap_values(data_P)\n",
    "shap_df = pd.DataFrame({'Feature': X.columns, 'SHAP Value': shap_values[0]})\n",
    "print(\"\\nSHAP Values:\")\n",
    "print(shap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(best_xgb_model, X_train)\n",
    "#explainer = shap.Explainer(xgb_classifier_saved, X_train)\n",
    "\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap_df = pd.DataFrame({'Feature': feature_names['0'].tolist(), 'SHAP Value': shap_values[0]})\n",
    "print(\"\\n SHAP Values:\")\n",
    "# Sort shap_df by the 'SHAP Value' column in ascending order\n",
    "sorted_shap_df = shap_df.sort_values(by='SHAP Value')\n",
    "\n",
    "# Print the sorted DataFrame\n",
    "print(sorted_shap_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508b0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_df.to_csv('3_Streamlit_dashboard/data/shap_df.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50cfcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, shap_df['Feature'], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc0a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade xgboost \n",
    "#pip install xgboost==1.7.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b13a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip freeze #> requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee89e9",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7 Feature Selection after SHAP feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973c53c",
   "metadata": {},
   "source": [
    "## Filter not useful features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49198917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the sorted DataFrame\n",
    "SHAP_feature_important_001 = shap_df[abs(shap_df['SHAP Value'])>0.001]['Feature'].tolist()\n",
    "len(SHAP_feature_important)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c288254",
   "metadata": {},
   "source": [
    "Retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded83c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(SHAP_feature_unimportant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6551c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(SHAP_feature_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f96f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP_feature_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb572c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2282a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_columns(X_train, feature_names, shap_df, threshold):\n",
    "    SHAP_feature_important = shap_df[abs(shap_df['SHAP Value'])>threshold]['Feature'].tolist()\n",
    "    print(\"length important features \", len(SHAP_feature_important))\n",
    "    df = X_train.copy()\n",
    "    df.columns = feature_names['0'].tolist()\n",
    "    df = df[SHAP_feature_important]\n",
    "    # Remove all column names\n",
    "    #df.rename(columns={x:y for x,y in zip(df.columns,range(0,len(df.columns)))})\n",
    "    df.columns = [x for x in range(0, len(df.columns))] \n",
    "    print(df.shape)\n",
    "    #print(df.info())\n",
    "    print(df.head())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10aaba6f",
   "metadata": {},
   "source": [
    "### First attempt to improve feature selection and model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6ef7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = select_columns(X_train, feature_names, shap_df, 0.001)\n",
    "new_X_test  = select_columns(X_test, feature_names, shap_df, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2578818",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"RFC_newFEATURE_001\"\n",
    "RFC_model_001, best_RFC_params, time_RFC = RFC_model(new_X_train, Y_train)\n",
    "RFC_metrics, best_metrics_RFC        = generate_model_report(RFC_model_001, run_name, new_X_test, Y_test, time_RFC)\n",
    "run_MLflow(experiment_name, run_name, RFC_metrics, \n",
    "           best_RFC_params, RFC_model_001, new_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa7eb0e",
   "metadata": {},
   "source": [
    "### Second attempt to improve feature selection and model improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dcb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train_002 = select_columns(X_train, feature_names, shap_df, 0.002)\n",
    "new_X_test_002  = select_columns(X_test, feature_names, shap_df, 0.002)\n",
    "\n",
    "X_train_002_scaled, X_test_002_scaled  = scale_data(new_X_train_002, new_X_test_002 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"RFC_newFEATURE_002\"\n",
    "RFC_model_002, best_RFC_params, time_RFC = RFC_model(new_X_train_002, Y_train)\n",
    "RFC_metrics, best_metrics_RFC            = generate_model_report(RFC_model_002, run_name, new_X_test_002, Y_test, time_RFC)\n",
    "run_MLflow(experiment_name, run_name, RFC_metrics, \n",
    "           best_RFC_params, RFC_model_002, new_X_train_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"XGB_Shap002\"\n",
    "XGB_model_002, XGB_002_params, time_XGB_002 = train_XGBoost_model(new_X_train_002, Y_train)\n",
    "XGB_002_metrics, best_metrics_XGB           = generate_model_report(XGB_model_002, run_name, new_X_test_002, Y_test, time_XGB_002)\n",
    "run_MLflow(experiment_name, run_name, XGB_002_metrics, \n",
    "           XGB_002_params, XGB_model_002, new_X_train_002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7f034",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"LGBM_Shap002\"\n",
    "LGBM_model_002, LGBM_002_params, time_LGBM_002 = train_LightGBM_model(new_X_train_002, Y_train)\n",
    "LGBM_002_metrics, best_metrics_LGBM           = generate_model_report(LGBM_model_002, run_name, new_X_test_002, Y_test, time_LGBM_002)\n",
    "run_MLflow(experiment_name, run_name, LGBM_002_metrics, \n",
    "           LGBM_002_params, LGBM_model_002, new_X_train_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2591fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train_002.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0dc7d2",
   "metadata": {},
   "source": [
    "## Run with Shap filtered and scaled data to assess impact on metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6d3e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_002_scale, X_test_002_scale = scale_data(new_X_train_002, new_X_test_002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac17be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"LGBM_Shap002_scaled\"\n",
    "#LGBM_model_002_scale, LGBM_002_scale_params, time_LGBM_002 = train_LightGBM_model(X_train_002_scale, Y_train)\n",
    "#LGBM_002_scale_metrics, best_metrics_LGBM_scale           = generate_model_report(LGBM_model_002_scale, run_name, X_test_002_scale, Y_test, time_LGBM_002)\n",
    "run_MLflow(experiment_name, run_name, LGBM_002_scale_metrics, \n",
    "           LGBM_002_scale_params, LGBM_model_002_scale, X_train_002_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850543a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8270d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"XGB_Shap002_scaled\"\n",
    "XGB_model_002_scaled, XGB_002_scaled_params, time_XGB_002_scaled = train_XGBoost_model(X_train_002_scale, Y_train)\n",
    "XGB_002_scaled_metrics, best_metrics_XGB_scaled           = generate_model_report(XGB_model_002_scaled, run_name, X_test_002_scale, Y_test, time_XGB_002_scaled)\n",
    "run_MLflow(experiment_name, run_name, XGB_002_scaled_metrics, \n",
    "           XGB_002_scaled_params, XGB_model_002_scaled, X_train_002_scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8233f52e",
   "metadata": {},
   "source": [
    "## Test MLflow on Fastapi model serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b56318",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://127.0.0.1:8000/predict -H 'Content-Type: application/json' -d '{\"inputs\": [[0, 0, 1, 1, 63000.0, 310500.0, 15232.5, 310500.0, 0.026392, 16263, -214.0, -8930.0, -573, 0.0, 1, 1, 0, 1, 1, 0, 2.0, 2, 2, 11, 0, 0, 0, 0, 1, 1, 0.0, 0.0765011930557638, 0.0005272652387098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false]]}'\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2780b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://127.0.0.1:8000/predict -H 'Content-Type: application/json' -d '{\"data_point\": [[0, 0, 1, 1, 63000.0, 310500.0, 15232.5, 310500.0, 0.026392, 16263, -214.0, -8930.0, -573, 0.0, 1, 1, 0, 1, 1, 0, 2.0, 2, 2, 11, 0, 0, 0, 0, 1, 1, 0.0, 0.0765011930557638, 0.0005272652387098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false]]}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b8851",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52314e2d",
   "metadata": {},
   "source": [
    "**Selection of a data point for testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4718bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = X_train.copy()\n",
    "test[\"ID\"] = ids_test\n",
    "test.set_index(\"ID\", inplace=True)\n",
    "ids_test.iloc[5]\n",
    "#test.loc[100008].values.tolist()\n",
    "data_for_request = test.loc[100030].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a4a0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_for_request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5b7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# initialised with: mlflow models serve -m model_LGBM02/ --port 8092\n",
    "#http://127.0.0.1:8092\n",
    "\n",
    "host = '127.0.0.1'\n",
    "port = '8000'\n",
    "\n",
    "# endpoint\n",
    "url = f'http://{host}:{port}/predict'\n",
    "print(\"URI : \", url)\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "# Send the POST request with the data\n",
    "response = requests.post(url, json={\"data_point\": data_for_request})\n",
    "\n",
    "print(f'Predictions: {response.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9329b5",
   "metadata": {},
   "source": [
    "**TEST with empty data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the POST request with the data\n",
    "response = requests.post(url, json={\"data_point\":[]})\n",
    "\n",
    "print(f'Predictions: {response.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c9c2b4",
   "metadata": {},
   "source": [
    "**TEST on hosting environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e705243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://fastapi-cd-webapp.azurewebsites.net/predict'\n",
    "# Send the POST request with the data\n",
    "response = requests.post(url, json={\"data_point\": data_for_request})\n",
    "\n",
    "print(f'Predictions: {response.text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be404e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
